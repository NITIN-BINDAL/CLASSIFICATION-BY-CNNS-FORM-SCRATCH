{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUPLE OF NECESSARY IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/nitinbindal/Downloads/dataset/Training\"  #Training folder path to your dataset\n",
    "categories = [\"Apple Golden 1\",\"Apple Golden 2\",\"Apple Golden 3\"]\n",
    "img_array=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the images into an array to perform CNNs\n",
    "for category in categories:\n",
    "    print(categories.index(category))\n",
    "    path = os.path.join(datadir,category)\n",
    "    class_num = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array.append([io.imread(os.path.join(path,img)),class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.shuffle(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir2 = \"/home/nitinbindal/Downloads/dataset/Test\"   #Test folder path of your dataset\n",
    "test_arr =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(datadir2,category)\n",
    "    class_num = categories.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        test_arr.append([io.imread(os.path.join(path,img)),class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec,vals=3):     #Performing one hot encoding\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n,vals))\n",
    "    out[range(n),vec]=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images =[]\n",
    "training_labels =[]\n",
    "test_images =[]\n",
    "test_labels =[]\n",
    "batch_size =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in data:\n",
    "    training_images.append(features)\n",
    "    training_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,label in test_arr:\n",
    "    test_images.append(feature)\n",
    "    test_labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array(test_images)/255     # --NORMALIZATION OF RGB\n",
    "test_label = one_hot_encode(np.hstack(np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=np.array(training_images)/255\n",
    "dat[0:50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class next_func:\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        self.training_images = np.array(training_images)/255      # --NORMALIZATION OF RGB\n",
    "        self.training_labels = one_hot_encode(np.hstack(np.array(training_labels)))\n",
    "    def next_batch(self,batch_size):\n",
    "        X = self.training_images[self.i:self.i + batch_size]\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = next_func() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,100,100,3])    #None is batch-size\n",
    "y = tf.placeholder(tf.float32,[None,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    rand_list = tf.truncated_normal(shape=shape,stddev=0.1)\n",
    "    return tf.Variable(rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    rand_list = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool(X):\n",
    "    return tf.nn.avg_pool(X,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x,shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_layer(input_x,neurons,actf=None):\n",
    "    return tf.layers.dense(input_x,neurons,activation = actf,kernel_initializer=he_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(X,[5,5,3,32])\n",
    "pool1 = avg_pool(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(pool1,[5,5,32,64])\n",
    "pool2 = avg_pool(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_3 = convolutional_layer(pool2,[7,7,64,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_3_flat = tf.reshape(convo_3,[-1,25*25*128])   #On 100 by 100 pixels you have applied 2 times avg_pooling means half the size each time hence (100/2)/2=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected = normal_layer(convo_3_flat,2048,actf = tf.nn.elu)  #USING LEAKY RELU FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = tf.nn.dropout(fully_connected,keep_prob = hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_layer(dropout,3,actf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred,labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate =0.0001)\n",
    "train_op = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.98)  #USE THIS OPTION ONLY WHEN YOUR TENSORFLOW IS INSTALLED ON GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for i in range(1200):\n",
    "        X_batch,y_batch = fb.next_batch(batch_size)\n",
    "        sess.run(train_op,feed_dict={X:X_batch,y:y_batch,hold_prob:0.5})\n",
    "        print(i)\n",
    "        if i%100 ==0:\n",
    "            print(\"STEP :{}\".format(i))\n",
    "            correct = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "            print(accuracy.eval(feed_dict={X:test_image,y:test_label,hold_prob:1.0}))\n",
    "            print(\"\\n\")\n",
    "        \n",
    "     #Highest accepted accuracy is 99.7955% if you can increase this let me know that!!!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
